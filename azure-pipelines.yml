# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

pool:
  vmImage: ubuntu-latest

steps:

- script: |
    echo "Calling Repos Update API to update branch."
    curl -n -X PATCH https://e2-dogfood.staging.cloud.databricks.com/api/2.0/repos/2351388579479538 \
      -H 'Authorization: Bearer '$(DATABRICKS-PAT) \
      -d '{"branch": "master"}'
  env: 
    DATABRICKS-PAT: $(DATABRICKS-PAT)

  displayName: 'Update Repos to latest'

- script: |
    echo "Calling Jobs RunsSubmit API to start a job."
    curl -n -X POST https://e2-dogfood.staging.cloud.databricks.com/api/2.1/jobs/runs/submit \
     -H 'Authorization: Bearer '$(DATABRICKS-PAT) \
     -d '{"tasks": [
        {
          "task_key": "Abby Wine Acid Analysis",
          "new_cluster": {
            "spark_version": "7.3.x-scala2.12",
            "node_type_id": "i3.xlarge",
            "spark_conf": {
              "spark.speculation": true
            },
          "aws_attributes": {
            "availability": "SPOT",
            "zone_id": "us-west-2a"
          },
          "autoscale": {
            "min_workers": 2,
            "max_workers": 16
          }
        },
        "notebook_task": {
          "notebook_path": "/Repos/zi.dong@databricks.com/files-dogfooding/Abby - Wine acid analysis"
        },
        "timeout_seconds": 86400
      }
    ]}'
  env: 
      DATABRICKS-PAT: $(DATABRICKS-PAT)
  displayName: 'Run job on updated Repos'